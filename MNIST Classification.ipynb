{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ff649d",
   "metadata": {},
   "source": [
    "## Lets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4747cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import sklearn\n",
    "\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ffde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist.data, mnist.target\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de1ef87",
   "metadata": {},
   "source": [
    "Lets take a peek at one single picture in the data. All we got to do is grab an instance feature vector shape it to 28*28 and display by matplotlib class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663dfabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digit(image_data):\n",
    "    image = image_data.values.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "some_digit = X.iloc[0]\n",
    "plot_digit(some_digit)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db97ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf421d1",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier\n",
    "Lets classify whether the number is 5 or not 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == '5')  # True for all 5s, False for all other digits\n",
    "y_test_5 = (y_test == '5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb84d4aa",
   "metadata": {},
   "source": [
    "### Lets use SGD Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b092bd64",
   "metadata": {},
   "source": [
    "This classifier\n",
    "has the advantage of being capable of handling very large datasets efficiently. This is\n",
    "in part because SGD deals with training instances independently, one at a time\n",
    "(which also makes SGD well suited for online learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6086a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92188da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39084b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00e898",
   "metadata": {},
   "source": [
    "The results here can be very delusional as lets take an example of a very dumb classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b18984",
   "metadata": {},
   "outputs": [],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf,X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2065a0",
   "metadata": {},
   "source": [
    "This demonstrates why accuracy is generally not the preferred performance measure\n",
    "for classifiers, especially when you are dealing with skewed datasets (i.e., when some\n",
    "classes are much more frequent than others)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a6185",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    " A much better way is to look at the confusion matrix i.e count the number of times instances of class A are classified as class B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c936e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04eeb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make the confusion matrix now on the predicted values and the actual values\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c00dd",
   "metadata": {},
   "source": [
    "The confusion matrix gives you a lot of information, but sometimes you may prefer a\n",
    "more concise metric. An interesting one to look at is the accuracy of the positive pre‐\n",
    "dictions; this is called the precision of the classifier \n",
    "\n",
    "precision = TP/(TP + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01da32",
   "metadata": {},
   "source": [
    "## Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c158aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821a0c55",
   "metadata": {},
   "source": [
    "It is often convenient to combine precision and recall into a single metric called the F1\n",
    "score, in particular if you need a simple way to compare two classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae81473",
   "metadata": {},
   "source": [
    "`The F1 score is the harmonic mean of precision and recall` \n",
    "\n",
    "As a result, the classifier will only get a high F1\n",
    " score if both recall and precision are\n",
    "high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94794dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ec2b9",
   "metadata": {},
   "source": [
    "The F1\n",
    "score favors classifiers that have similar precision and recall. This is not always\n",
    "what you want: in some contexts you mostly care about precision, and in other con‐\n",
    "texts you really care about recall. \n",
    "\n",
    "For example, if you trained a classifier to detect vid‐\n",
    "eos that are safe for kids, you would probably prefer a classifier that rejects many\n",
    "good videos (low recall) but keeps only safe ones (high precision), rather than a clas‐\n",
    "sifier that has a much higher recall but lets a few really bad videos show up in your\n",
    "product (in such cases, you may even want to add a human pipeline to check the clas‐\n",
    "sifier’s video selection). \n",
    "\n",
    "On the other hand, suppose you train a classifier to detect\n",
    "shoplifters in surveillance images: it is probably fine if your classifier has only 30%\n",
    "precision as long as it has 99% recall (sure, the security guards will get a few false\n",
    "alerts, but almost all shoplifters will get caught).\n",
    "Unfortunately, you can’t have it both ways: increasing precision reduces recall, and\n",
    "vice versa. \n",
    "\n",
    "`This is called the precision/recall trade-off.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8df78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try using the decision_function\n",
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "y_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88393ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 8000\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15514eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
    " method=\"decision_function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aafbbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ad261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    " plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    " plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    " plt.xlabel(\"Threshold\")\n",
    " plt.ylabel(\"Values\")\n",
    " plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2f7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_90 = (y_scores>=threshold_90_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e618491",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116197c",
   "metadata": {},
   "source": [
    "If someone says, “Let’s reach 99% precision,” you should ask, “At\n",
    "what recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5989e",
   "metadata": {},
   "source": [
    "### The ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93828a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.xlabel(\"False Positive Rate \")\n",
    "    plt.ylabel(\"True Positive rate (recall)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6adbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves(fpr,tpr)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate the area under the curve\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772985e",
   "metadata": {},
   "source": [
    "`Since the ROC curve is so similar to the precision/recall (PR)\n",
    "curve, you may wonder how to decide which one to use. As a rule\n",
    "of thumb, you should prefer the PR curve whenever the positive\n",
    "class is rare or when you care more about the false positives than\n",
    "the false negatives. Otherwise, use the ROC curve. For example,\n",
    "looking at the previous ROC curve (and the ROC AUC score), you\n",
    "may think that the classifier is really good. But this is mostly\n",
    "because there are few positives (5s) compared to the negatives\n",
    "(non-5s). In contrast, the PR curve makes it clear that the classifier\n",
    "has room for improvement (the curve could be closer to the topleft corner).`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e32b9",
   "metadata": {},
   "source": [
    "Lets use randomForestclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b85174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
    " method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_forest = y_probas_forest[:,1]\n",
    "fpr_forest, tpr_forest, threshold_forest = roc_curve(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, 'b:', label=\"SGD\")\n",
    "plot_roc_curves(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d849e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions_forest, recalls_forest, thresholds_forest= precision_recall_curve(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c60db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_vs_threshold(precisions_forest, recalls_forest,thresholds_forest)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ce449",
   "metadata": {},
   "source": [
    "## Multiclass Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e05e402",
   "metadata": {},
   "source": [
    "Some algorithms (such as SGD classifiers, Random Forest classifiers, and naive Bayes\n",
    "classifiers) are capable of handling multiple classes natively. Others (such as Logistic\n",
    "Regression or Support Vector Machine classifiers) are strictly binary classifiers. How‐\n",
    "ever, there are various strategies that you can use to perform multiclass classification\n",
    "with multiple binary classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8328c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train, y_train) # y_train, not y_train_5\n",
    "svm_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ce533",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit_scores = svm_clf.decision_function([some_digit])\n",
    "some_digit_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(some_digit_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae03363",
   "metadata": {},
   "source": [
    "If you want to force Scikit-Learn to use one-versus-one or one-versus-the-rest, you\n",
    "can use the OneVsOneClassifier or OneVsRestClassifier classes. Simply create an\n",
    "instance and pass a classifier to its constructor (it does not even have to be a binary\n",
    "classifier). For example, this code creates a multiclass classifier using the OvR strat‐\n",
    "egy, based on an SVC:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_clf = OneVsRestClassifier(SVC())\n",
    "ovr_clf.fit(X_train, y_train)\n",
    "ovr_clf.predict([some_digit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68be361",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ovr_clf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69283c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb699a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.decision_function([some_digit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    " cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc0bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
